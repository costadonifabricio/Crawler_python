## Web Crawler Python
El objetivo de este trabajo es implementar un web crawler en Python que pueda
recorrer un sitio web, extraer todas las etiquetas "a" con sus respectivos enlaces y acceder a cada página enlazada. Por cada enlace encontrado, se deben obtener todas las etiquetas "h1" y "p" y almacenarlo en un array en un archivo JSON y si no se encuentran dichos elementos guardar el array como vacío.

## Requisitos

- Python 3 o superior
- BeautifulSoup4
- requests

## Instalación

1. Clona este repositorio en tu máquina local usando `https://github.com/costadonifabricio/Crawler_python.git`
2. Navega hasta el directorio del proyecto
3. Crea un Entorno Virtual para instalar las dependencias
4. Instala las dependencias necesarias con pip: `pip install`

